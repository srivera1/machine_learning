{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "#\n",
    "# characteristics:\n",
    "#    ensembled CNN\n",
    "#    29700 parameters \n",
    "#    input trained with 5% noise\n",
    "#    parametrized neural network generation\n",
    "# \n",
    "# results:\n",
    "#    val_acc: 0.9935%\n",
    "#\n",
    "# 2019/08/06 by srivera\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras import activations\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Dropout, Flatten, Concatenate, Reshape, concatenate, Maximum, Permute\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D, MaxPooling1D\n",
    "import keras.utils.np_utils as kutils\n",
    "from keras.utils import np_utils, plot_model\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 200 # 10\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "NOISE = 0.050\n",
    "x_train = x_train.astype('float32') # la imagen de marsee tiene offset\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_train += np.random.normal(0.0,NOISE,x_train.shape) + np.random.normal(0.0,NOISE,1)[0]\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 10)        500       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 22, 22, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 10)        2510      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 10)          910       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5, 5, 10)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,950\n",
      "Trainable params: 4,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.5056 - acc: 0.8329 - val_loss: 0.1558 - val_acc: 0.9531\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.1231 - acc: 0.9625 - val_loss: 0.0866 - val_acc: 0.9729\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0917 - acc: 0.9726 - val_loss: 0.0731 - val_acc: 0.9762\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0765 - acc: 0.9768 - val_loss: 0.0714 - val_acc: 0.9764\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0666 - acc: 0.9796 - val_loss: 0.0579 - val_acc: 0.9809\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0587 - acc: 0.9817 - val_loss: 0.0534 - val_acc: 0.9832\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0535 - acc: 0.9841 - val_loss: 0.0489 - val_acc: 0.9844\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0494 - acc: 0.9846 - val_loss: 0.0495 - val_acc: 0.9847\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0454 - acc: 0.9861 - val_loss: 0.0442 - val_acc: 0.9863\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0426 - acc: 0.9869 - val_loss: 0.0421 - val_acc: 0.9860\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0393 - acc: 0.9881 - val_loss: 0.0411 - val_acc: 0.9865\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.0376 - acc: 0.9885 - val_loss: 0.0421 - val_acc: 0.9863\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0348 - acc: 0.9895 - val_loss: 0.0396 - val_acc: 0.9879\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0343 - acc: 0.9896 - val_loss: 0.0391 - val_acc: 0.9869\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0320 - acc: 0.9902 - val_loss: 0.0432 - val_acc: 0.9862\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0303 - acc: 0.9908 - val_loss: 0.0500 - val_acc: 0.9837\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0291 - acc: 0.9914 - val_loss: 0.0398 - val_acc: 0.9879\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0277 - acc: 0.9912 - val_loss: 0.0440 - val_acc: 0.9865\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0273 - acc: 0.9913 - val_loss: 0.0422 - val_acc: 0.9867\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0254 - acc: 0.9924 - val_loss: 0.0403 - val_acc: 0.9880\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0247 - acc: 0.9923 - val_loss: 0.0383 - val_acc: 0.9883\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0234 - acc: 0.9927 - val_loss: 0.0405 - val_acc: 0.9879\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0227 - acc: 0.9930 - val_loss: 0.0381 - val_acc: 0.9889\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0213 - acc: 0.9936 - val_loss: 0.0388 - val_acc: 0.9889\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0202 - acc: 0.9941 - val_loss: 0.0381 - val_acc: 0.9885\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0198 - acc: 0.9938 - val_loss: 0.0397 - val_acc: 0.9890\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0181 - acc: 0.9944 - val_loss: 0.0381 - val_acc: 0.9890\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0177 - acc: 0.9947 - val_loss: 0.0409 - val_acc: 0.9894\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0169 - acc: 0.9945 - val_loss: 0.0470 - val_acc: 0.9878\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0162 - acc: 0.9951 - val_loss: 0.0417 - val_acc: 0.9884\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0160 - acc: 0.9953 - val_loss: 0.0415 - val_acc: 0.9891\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0155 - acc: 0.9949 - val_loss: 0.0497 - val_acc: 0.9864\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0152 - acc: 0.9951 - val_loss: 0.0412 - val_acc: 0.9887\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0139 - acc: 0.9960 - val_loss: 0.0439 - val_acc: 0.9881\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0136 - acc: 0.9956 - val_loss: 0.0427 - val_acc: 0.9886\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0445 - val_acc: 0.9885\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.0437 - val_acc: 0.9891\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0449 - val_acc: 0.9884\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0120 - acc: 0.9962 - val_loss: 0.0481 - val_acc: 0.9887\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0106 - acc: 0.9966 - val_loss: 0.0507 - val_acc: 0.9870\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0108 - acc: 0.9963 - val_loss: 0.0537 - val_acc: 0.9888\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0102 - acc: 0.9965 - val_loss: 0.0469 - val_acc: 0.9880\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0095 - acc: 0.9970 - val_loss: 0.0486 - val_acc: 0.9885\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0476 - val_acc: 0.9885\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0090 - acc: 0.9970 - val_loss: 0.0474 - val_acc: 0.9884\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0515 - val_acc: 0.9875\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0082 - acc: 0.9976 - val_loss: 0.0492 - val_acc: 0.9871\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.0546 - val_acc: 0.9875\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.0495 - val_acc: 0.9884\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.0573 - val_acc: 0.9883\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0520 - val_acc: 0.9890\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.0553 - val_acc: 0.9877\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0571 - val_acc: 0.9872\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0530 - val_acc: 0.9883\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0550 - val_acc: 0.9870\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0540 - val_acc: 0.9884\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0582 - val_acc: 0.9880\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0647 - val_acc: 0.9876\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0578 - val_acc: 0.9882\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.0710 - val_acc: 0.9856\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0594 - val_acc: 0.9888\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0648 - val_acc: 0.9868\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0613 - val_acc: 0.9883\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0632 - val_acc: 0.9886\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0635 - val_acc: 0.9887\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0653 - val_acc: 0.9869\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0646 - val_acc: 0.9882\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0631 - val_acc: 0.9880\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0648 - val_acc: 0.9878\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0628 - val_acc: 0.9879\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0666 - val_acc: 0.9884\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0617 - val_acc: 0.9877\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0649 - val_acc: 0.9879\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0675 - val_acc: 0.9877\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0675 - val_acc: 0.9881\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0706 - val_acc: 0.9882\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0707 - val_acc: 0.9887\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0783 - val_acc: 0.9867\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0752 - val_acc: 0.9865\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0755 - val_acc: 0.9878\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0707 - val_acc: 0.9879\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0694 - val_acc: 0.9879\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0749 - val_acc: 0.9871\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0683 - val_acc: 0.9883\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0726 - val_acc: 0.9880\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0717 - val_acc: 0.9880\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0724 - val_acc: 0.9885\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 0.0851 - val_acc: 0.9865\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0750 - val_acc: 0.9881\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0765 - val_acc: 0.9880\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0770 - val_acc: 0.9878\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0814 - val_acc: 0.9865\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0809 - val_acc: 0.9880\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0788 - val_acc: 0.9882\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0772 - val_acc: 0.9881\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0788 - val_acc: 0.9879\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0820 - val_acc: 0.9873\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0816 - val_acc: 0.9873\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0843 - val_acc: 0.9884\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0848 - val_acc: 0.9883\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 8.6883e-04 - acc: 0.9999 - val_loss: 0.0860 - val_acc: 0.9883\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0908 - val_acc: 0.9872\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0851 - val_acc: 0.9882\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0895 - val_acc: 0.9869\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0848 - val_acc: 0.9880\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0891 - val_acc: 0.9874\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0866 - val_acc: 0.9878\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0848 - val_acc: 0.9880\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0875 - val_acc: 0.9877\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0879 - val_acc: 0.9872\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0878 - val_acc: 0.9879\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.1017 - val_acc: 0.9865\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0912 - val_acc: 0.9875\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0902 - val_acc: 0.9875\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.1061 - val_acc: 0.9857\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0872 - val_acc: 0.9883\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 9.9171e-04 - acc: 0.9998 - val_loss: 0.0916 - val_acc: 0.9881\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.1017 - val_acc: 0.9861\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0876 - val_acc: 0.9877\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0986 - val_acc: 0.9866\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0913 - val_acc: 0.9878\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 9.8943e-04 - acc: 0.9998 - val_loss: 0.0974 - val_acc: 0.9875\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0920 - val_acc: 0.9871\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 7.9866e-04 - acc: 0.9999 - val_loss: 0.0934 - val_acc: 0.9880\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0943 - val_acc: 0.9880\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 8.5097e-04 - acc: 0.9998 - val_loss: 0.0982 - val_acc: 0.9880\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 8.8291e-04 - acc: 0.9998 - val_loss: 0.0968 - val_acc: 0.9882\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0929 - val_acc: 0.9874\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0954 - val_acc: 0.9877\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 8.9001e-04 - acc: 0.9998 - val_loss: 0.0932 - val_acc: 0.9878\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 8.4783e-04 - acc: 0.9998 - val_loss: 0.0957 - val_acc: 0.9874\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0931 - val_acc: 0.9877\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 9.4679e-04 - acc: 0.9998 - val_loss: 0.1001 - val_acc: 0.9876\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 7.5068e-04 - acc: 0.9998 - val_loss: 0.0897 - val_acc: 0.9882\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0921 - val_acc: 0.9877\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 7.2783e-04 - acc: 0.9999 - val_loss: 0.0965 - val_acc: 0.9868\n",
      "Epoch 137/200\n",
      "46208/60000 [======================>.......] - ETA: 0s - loss: 0.0011 - acc: 0.9998"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype('int32')\n",
    "y_test  = y_test.astype('int32')\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test  = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# the goal is to produce a model that is simple\n",
    "# and composed of submodels not interconnected, \n",
    "# except for the input and the output layers \n",
    "# (since later I produce digital hardware that \n",
    "# runs the NN).\n",
    "\n",
    "def subModelGenerator():\n",
    "    subModel=[]\n",
    "    subModel.append(Input(shape=(28, 28, 1), name=\"input\"))\n",
    "    Nlayers = 3\n",
    "    for i in range(Nlayers):\n",
    "        if i == 0:\n",
    "            subModel.append(Conv2D(10,(7,7), padding=\"valid\", input_shape=(28, 28,1), \n",
    "                               kernel_initializer=\"glorot_uniform\")(subModel[-1]))\n",
    "        else:\n",
    "            subModel.append(Conv2D(10,(7-i*2,7-i*2), padding=\"same\", kernel_initializer=\"glorot_uniform\")(subModel[-1]))\n",
    "            \n",
    "        subModel.append(Activation(activation='relu')(subModel[-1]))\n",
    "        subModel.append(MaxPooling2D(pool_size=(2,2))(subModel[-1]))\n",
    "        \n",
    "    subModel.append(Flatten()(subModel[-1]))\n",
    "    subModel.append(Dense(20, kernel_initializer=\"glorot_uniform\")(subModel[-1]))\n",
    "    subModel.append(Activation(activation='relu')(subModel[-1]))\n",
    "    subModel.append(Dense(num_classes, kernel_initializer=\"glorot_uniform\")(subModel[-1]))\n",
    "    subModel.append(Activation(activation='softmax')(subModel[-1]))\n",
    "    \n",
    "    model = Model(inputs=subModel[0], outputs=subModel[-1])\n",
    "    optimizer=keras.optimizers.Adadelta(lr=0.990, rho=0.95, epsilon=None, decay=0.0)#,0.3015\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "          verbose=1, validation_data=(x_test, y_test))\n",
    "    return model\n",
    "\n",
    "Nsubmodels = 6\n",
    "models=[]\n",
    "for i in range(Nsubmodels):\n",
    "    models.append(subModelGenerator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 10)           4950        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 10)           4950        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Model)                 (None, 10)           4950        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 10)           4950        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "model_5 (Model)                 (None, 10)           4950        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "model_6 (Model)                 (None, 10)           4950        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 60)           0           model_1[1][0]                    \n",
      "                                                                 model_2[1][0]                    \n",
      "                                                                 model_3[1][0]                    \n",
      "                                                                 model_4[1][0]                    \n",
      "                                                                 model_5[1][0]                    \n",
      "                                                                 model_6[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 6, 10)        0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 10)        0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1, 10)        0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 10)           0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 10)           0           flatten_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 29,700\n",
      "Trainable params: 0\n",
      "Non-trainable params: 29,700\n",
      "__________________________________________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 1.4612 - acc: 1.0000 - val_loss: 1.4678 - val_acc: 0.9935\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x4320 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 1\n",
    "\n",
    "output=[]\n",
    "B=[]\n",
    "B.append(Input(shape=(28, 28, 1), name=\"input\"))\n",
    "\n",
    "for i in range(Nsubmodels):\n",
    "    A=[]\n",
    "    for l in models[i].layers:\n",
    "        l.trainable = False\n",
    "    A.append(models[i](B[0]))\n",
    "    A[-1].trainable = False\n",
    "    output.append(A[-1])\n",
    "    \n",
    "\n",
    "B.append(concatenate(output))\n",
    "B.append(Reshape((Nsubmodels,10))(B[-1]))\n",
    "B.append(Permute((1, 2))(B[-1]))\n",
    "B.append(MaxPooling1D(pool_size=(Nsubmodels))(B[-1]))\n",
    "B.append(Flatten()(B[-1]))\n",
    "B.append(Activation(activation='softmax')(B[-1]))\n",
    "model = Model(inputs=B[0],outputs=B[-1])\n",
    "model.summary()\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "plt.figure(figsize=(15,60))\n",
    "x=plt.imread(\"model.png\")\n",
    "plt.imshow(x)\n",
    "\n",
    "optimizer=keras.optimizers.Adadelta(lr=0.990, rho=0.95, epsilon=None, decay=0.0)#,0.3015\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "          verbose=1, validation_data=(x_test, y_test))\n",
    "# fitting is just for testing, since there NN are already trainned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 28, 28, 1)\n",
      "[2 0 9 ... 3 9 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "x_test = test.values.astype('float32')\n",
    "x_test /= 255.\n",
    "#final_loss, final_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28,1)  \n",
    "\n",
    "print(x_test.shape)\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# prediction\n",
    "predicted_classes = model.predict(x_test)\n",
    "predicted_classes = np.argmax(predicted_classes,axis=1)\n",
    "print(predicted_classes)\n",
    "# submissions\n",
    "submissions = pd.DataFrame({\"ImageId\": list(range(1, len(predicted_classes)+1)),\n",
    "                           \"Label\": predicted_classes})\n",
    "submissions.to_csv(\"mnistSubmission.csv\", index = False, header = True)\n",
    "\n",
    "# save model\n",
    "model.save('model.h5')\n",
    "\n",
    "# json model\n",
    "json_string = model.to_json()\n",
    "\n",
    "len(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kaggle as kg\n",
    "# kg competitions submit -c digit-recognizer -f mnistSubmission.csv -m \"MNIST, ensembled CNN, 29700 parameters, 5 percent noise, parametrized neural network, by srivera\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
